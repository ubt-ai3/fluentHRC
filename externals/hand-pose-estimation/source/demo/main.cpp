#include <filesystem>
#include <boost/timer/timer.hpp>

#include <pcl/common/transforms.h>
#include "kinect2_grabber.h"

#include "calibration.hpp"

#include "hand_pose.hpp"
#include "hand_pose_estimation/hand_tracker.hpp"
#include "hand_pose_estimation/finger_detection.hpp"
// #define DEBUG_BUFFER_INPUT

using namespace hand_pose_estimation;

Eigen::Matrix<float, 3, 4> projection_matrix(const kinect2_parameters& kinect2_params,
	const cv::MatSize& size)
{
	// kinect2_params.rgb_projection has its origin in the bottom right of the image, we need it in the top left
	Eigen::Translation2f center(size[1] * 0.5f, size[0] * 0.5f);
	return  center * Eigen::Affine2f(Eigen::Rotation2D<float>(M_PI)) * center.inverse() * kinect2_params.rgb_projection;
}


/*
	main function for recognizing images
*/
int hand_gesture_recognition_main(int argc, char* argv[])
{
	typedef pcl::PointXYZRGBA PointT;

	kinect2_parameters kinect2_params;
	Eigen::Hyperplane<float, 3> background_plane(Eigen::Vector3f(-1.864541089e-03, 2.896448970e-01, -9.571323395e-01), 1.191677570e+00);
	
	Eigen::Matrix4d cloud_transformation = Eigen::Matrix4d();
	//generated by registration.cpp via red cube tracking from project vc19b in file computed_workspace_params in assets folder
	cloud_transformation <<
		9.988893270e-01,
		-1.936255395e-02,
		-4.295487702e-02,
		1.358819455e-01,
		-3.669373691e-02,
		-8.915637732e-01,
		-4.514075220e-01,
		8.463665843e-01,
		-2.955661528e-02,
		4.524823427e-01,
		-8.912841082e-01,
		6.867195964e-01,
		0.000000000e+00,
		0.000000000e+00,
		0.000000000e+00,
		1.000000000e+00;
	Eigen::Affine3f transformation(cloud_transformation.cast<float>());
	Eigen::Vector3f normal = transformation.rotation().inverse().col(2);

	Eigen::Hyperplane<float, 3> table_plane (normal, -normal.dot(transformation.translation()));

	//hand_tracker hand_track(1.f, 4, Eigen::Vector3f(0.f, 0.f, -1.f), background_plane);

	hand_pose_test hand_pos_test;

	auto viewer = pcl::make_shared<pcl::visualization::PCLVisualizer>("Viewer");
	viewer->setCameraPosition(0.0, 0.0, 3.5, 0.0, 1.0, 0.0);
	viewer->addCoordinateSystem();


	// Point Cloud
	pcl::PointCloud<PointT>::ConstPtr cloud;
	pcl::ModelCoefficients line_coordinates;
	PointT finger_start, finger_end;
#ifdef DEBUG_BUFFER_INPUT
	std::list<visual_input::Ptr> input;
#else
	visual_input::Ptr input;
#endif
	bool updated = false;

	// Retrieved Point Cloud Callback Function
	std::mutex mutex;
	std::function<void(const pcl::PointCloud<PointT>::ConstPtr&)> pc_grabber =
		[&cloud, &mutex,&viewer,cloud_transformation,table_plane](const pcl::PointCloud<PointT>::ConstPtr& ptr) {
		std::lock_guard<std::mutex> lock(mutex);

		if (!ptr || ptr->header.stamp == 0)
			return;

		if (!cloud || cloud->header.stamp != ptr->header.stamp)
		{
			std::cout << " new cloud\n";
			//Eigen::Matrix4f t = cloud_transformation.cast<float>();
			//auto transformed_pc = std::make_shared<pcl::PointCloud<PointT>>();
			//pcl::transformPointCloud(*ptr, *transformed_pc, t);
			//pcl::transformPointCloud()
			//cloud = transformed_pc;
			cloud = ptr;

		}

	};

	pointing_gesture_detector detect;
	detect.table_plane = table_plane;
	detect.skin_detect.show_skin_regions();
	detect.skin_detect.true_skin_threshold = 0.5;
	detect.skin_detect.skin_threshold = 0.15;
	cv::Point tl(1920 * 9 / 45, 150);//discard the table as it is skinlike colored
	cv::Point br(1920 * 33 / 45, 1080);
	detect.roi = cv::Rect(tl, br);
	std::mutex show_image_mutex;
	std::atomic_bool calibrating = false;
	bool has_line = false;
	boost::function<void(const cv::Mat4b& input)> img_grabber =
		[&](const cv::Mat4b& img) {
		std::lock_guard<std::mutex> lock(mutex);

			
		if(img.rows && cloud)
		{
#ifdef DEBUG_BUFFER_INPUT
			input.push_back(std::make_shared<visual_input>(cloud, img, kinect2_params.rgb_projection, kinect2_params.depth_projection));
#else
			if (cv::waitKey(10) == 'c' && calibrating == false)
			{
				calibrating = true;
				std::cout << "Press w or s to change sensitivity\n";
				detect.skin_detect.calibrate_with_hand_image(img);
				calibrating = false;
			}
			// Combine point cloud and image into a structure for further processing
			input = std::make_shared<visual_input>(cloud, img, kinect2_params.rgb_projection, kinect2_params.depth_projection);
			//hand_track.update(input);
			if (input->has_cloud())
			{
				try
				{
					if (show_image_mutex.try_lock())
						show_image_mutex.unlock();
					else
						return;
					std::scoped_lock(show_image_mutex);


						auto res = detect.detect(*input);
						cv::imshow("Gesture", detect.visualization);
						int i = 0;

						//for (auto& mat : detect.evaluation_mat)
						//{
						//	cv::imshow("Eval " + std::to_string(i), mat);
						//	i++;
						//}
						cv::waitKey(1);

						if (res.empty())
							std::cout << "No gesture found\n";
						else
						{
							for (const auto& gesture : res)
							{
								//std::cout << "Finger tip: " << gesture.finger_tip << "\n";
								//std::cout << "Direction: " << gesture.pointing_direction << "\n";
								Eigen::Vector3f start = Eigen::Vector3f(gesture.finger_tip3D.x,gesture.finger_tip3D.y,gesture.finger_tip3D.z);
								Eigen::Vector3f end = Eigen::Vector3f(gesture.finger_root3D.x, gesture.finger_root3D.y, gesture.finger_root3D.z);

								Eigen::Vector3f dir = Eigen::Vector3f(gesture.pointing_direction3D.x,gesture.pointing_direction3D.y,gesture.pointing_direction3D.z);
								start = Eigen::Affine3f(cloud_transformation.cast<float>()) * start;
								end = Eigen::Affine3f(cloud_transformation.cast<float>()) * end;

								dir = Eigen::Matrix3f(cloud_transformation.cast<float>().block(0,0,3,3)) * dir.normalized();
								pcl::ModelCoefficients c;
								c.values.resize(6);
								c.values[0] = start[0];
								c.values[1] = start[1];
								c.values[2] = start[2];
								c.values[3] = dir[0];
								c.values[4] = dir[1];
								c.values[5] = dir[2];
								std::cout << "Finger tip: " << start<<"\n";
								std::cout << "Direction: " << dir << "\n";
								//viewer->addLine(gesture.finger_tip,gesture.finger_tip+gesture.pointing_direction *0.1,"line");
								line_coordinates = c;
								finger_start = PointT(start.x(), start.y(), start.z());
								finger_end = PointT(end.x(),end.y(),end.z());
								has_line = true;
							}
						}

						if (cv::waitKey(10) == 's')
						{
							std::cout << "pls enter a name for the file directory:\n";
							std::string dir_name;
							std::getline(std::cin, dir_name);

							std::vector<cv::Mat> to_save;

							std::string full_path = "C:\\Users\\wimmer\\BA Daten\\Evaluation\\Zeigegeste\\" + dir_name;

							for (auto& mat : detect.evaluation_mat)
								to_save.push_back(mat);
							to_save.push_back(detect.visualization);

							if (!std::filesystem::create_directory(full_path))
							{
								std::cout << "Failed creating directory!\n";
								return;
							}
							int id = 0;
							for (auto& mat : to_save)
							{
								cv::imwrite(full_path + "/" + std::to_string(id)+".PNG", mat);
								id++;
							}
						}
						std::cout << "\n";
				}
				catch (const std::exception& e)
				{
					std::cout << "Error:\n";
					std::cout << e.what();
				}
			}
#endif
			updated = true;
		}
	};

	// Kinect2Grabber
	std::shared_ptr<pcl::Grabber> grabber = pcl::make_shared<pcl::Kinect2Grabber>();

	// Register Callback Function
	boost::signals2::connection connection_pc = grabber->registerCallback(pc_grabber);
	boost::signals2::connection connection_img = grabber->registerCallback(img_grabber);


	// Start Grabber
	grabber->start();


	int counter = 0;
	while (!viewer->wasStopped()) {
		// Update Viewer
		try {
			viewer->spinOnce();
			counter++;
			//hand_viewer->spinOnce();
			if (counter % 16 == 0)
			{
				counter = 0;
				if (cloud)
				{
			
					if (!viewer->updatePointCloud(cloud))
						viewer->addPointCloud(cloud);
					viewer->updatePointCloudPose("cloud", Eigen::Affine3f(cloud_transformation.cast<float>()));
					if (has_line)
					{
						viewer->removeShape("line");
						viewer->addLine(line_coordinates, "line");
						viewer->removeShape("s1");
						viewer->addSphere(finger_start, 0.005,"s1");
						viewer->removeShape("s2");
						viewer->addSphere(finger_end, 0.005,"s2");
					}
				}
			}
		}
		catch (...) {
			continue;
		}

		visual_input::Ptr tmp_input = nullptr;

		{
			std::lock_guard<std::mutex> lock(mutex);
#ifdef DEBUG_BUFFER_INPUT
			if (!input.empty())
			{
				tmp_input = input.front();
				input.pop_front();
				hand_track->update(tmp_input);
			}
#else
			if(updated)
				tmp_input = input;
#endif
			updated = false; // check for new values in every rendering step
		}


		if (tmp_input)
		{

		//	hand_pos_test.show_hands(viewer, input, hand_track.get_hands());

			
			//cv::waitKey(1);
		}



	}

	// Stop Grabber
	grabber->stop();

	// Disconnect Callback Function
	if (connection_pc.connected()) {
		connection_pc.disconnect();
	}

	if (connection_img.connected()) {
		connection_img.disconnect();
	}

	return 0;
}

const char* print_size(const cv::Mat& mat)
{
	std::stringstream s;
	s << mat.size();
	static std::string str;
	str = s.str();
	return str.c_str();
}

//experimental function to detect edges in images
cv::Mat edge_detector(const cv::Mat& mat)
{
	cv::Mat contours;
	cv::Mat gray_image;

	std::vector<cv::Mat> channels;
	cv::Mat hsv;
	cv::cvtColor(mat, hsv, cv::COLOR_BGR2HSV);
	cv::Mat ycr;
	cv::cvtColor(mat, ycr, cv::COLOR_BGR2YCrCb);
	cv::split(ycr, channels);
	gray_image = channels[0];
	int lower = 40;
	int upper = 120;
	cv::Canny(gray_image, contours, 25, 200);

	cv::namedWindow("Image");
	cv::imshow("Image", mat);

	cv::namedWindow("Gray");
	cv::imshow("Gray", gray_image);

	cv::namedWindow("Canny");
	cv::imshow("Canny", contours);
	cv::Mat res_lap;
	//cv::Laplacian(gray_image, res_lap, CV_8U,3,2.0);
	//cv::namedWindow("Laplacian");
	//cv::imshow("Laplacian",res_lap);
	int c = 0;
	//do
	//{
	//	cv::Canny(gray_image, contours, lower, upper);
	//	cv::namedWindow("Canny");
	//	cv::imshow("Canny", contours);
	//	c = cv::waitKey();
	//	if (c == 'w')
	//		lower += 5;
	//	else if (c == 's')
	//		lower -= 5;
	//	else if (c == 'a')
	//		upper += 5;
	//	else if(c=='d')
	//		upper -= 5;
	//} 	while (c != ' ');
	//grad_x = cv2.Sobel(img, cv2.CV_64F, 1, 0)
	//	grad_y = cv2.Sobel(img, cv2.CV_64F, 0, 1)
	//	grad = np.sqrt(grad_x * *2 + grad_y * *2)
	//	grad_norm = (grad * 255 / grad.max()).astype(np.uint8)
	//	cv2.imshow('Edges', grad_norm)
	//	cv2.waitKey(0)
	return contours;
}

std::vector<cv::Mat> visualize_hand_detection(const cv::Mat& img)
{
	using namespace hand_pose_estimation;
	skin_detection_bayes detect;
	detect.show_skin_regions();


	try
	{

		//auto input = cv::imread("D:\\Bachelorarbeit Dokumente\\hand pictures\\yolse_fingertips_detection.PNG", cv::ImreadModes::IMREAD_ANYCOLOR);
		std::vector<cv::Mat> debug_mats;
		cv::Mat3b input3b;

		if (img.channels() == 4)
		{
			cv::cvtColor(img, input3b, cv::COLOR_BGRA2BGR);
		}
		else
			input3b = img;
		detect.skin_candidate(input3b);
		//auto mat = edge_detector(img);
		if (detect.get_regions().size())
		{
			auto& hand = detect.get_regions().back();
			
			//cv::Mat out;
			//cv::bitwise_and(hand, mat(detect.get_boxes().back()),out);
			//cv::imshow("t", out);
			//cv::waitKey();
			cv::imshow("Segmented Hand", hand);
			
			finger_detector finger_detect;
			auto res = finger_detect.detect(hand,debug_mats);
		//	if (res.bounding_boxes.size() == 1)
			for(auto box: res.bounding_boxes)
			{
				//transform finger in original coordinate system
				const auto& roi = detect.get_boxes().back();
				const auto& center = detect.get_centers().back();

				//auto& box = res.bounding_boxes[0].center;
				//box += cv::Point2f(detect.get_boxes().back().tl());

				cv::Mat3b image_with_finger;
				input3b.copyTo(image_with_finger);
				//cv::line(image_with_finger, roi.tl(), roi.br(),cv::Scalar(255,0,0));
				box.center += cv::Point2f(roi.tl());
				finger_detector::draw_rotated_rect(image_with_finger, box);
				cv::imshow("original",image_with_finger);
				
			}
			
			return debug_mats;
		}
		else
		{
			return {};
		}
		return {};
	}
	catch (std::exception& e)
	{
		std::cout << e.what();
		throw;
	}
}

/*
shows images from the kinect
*/
void extract_images_kinect()
{
	cv::namedWindow("Kinect");
	// Kinect2Grabber
	std::shared_ptr<pcl::Grabber> grabber = pcl::make_shared<pcl::Kinect2Grabber>();
	boost::function<void(const cv::Mat4b& input)> img_grabber =
		[](const cv::Mat4b& img) {
		cv::imshow("Kinect", img);
		//auto mats = visualize_hand_detection(img);
		//int i = 0;
		//for (const auto& mat : mats)
		//{
		//	cv::imshow(std::string{ "Test" }+std::to_string(i), mat);
		//	cv::waitKey(500);
		//	i++;
		//}
		cv::waitKey(1);

	};
	
	grabber->registerCallback(img_grabber);
	grabber->start();
	while(' ' != cv::waitKey(0));

	std::cout << "finished\n";
	grabber->stop();
}

/*
* goes for each picture in @param folder and applies gesture recognition on it
* results are shown and written to the parent folder of @param folder
*/
void process_images(std::filesystem::path folder)
{
	using namespace  std::filesystem;
	if (!is_directory(folder)|| !exists(folder))
	{
		std::cout << "folder not found or not a folder\n";
		return;
	}

	auto new_folder = folder.parent_path();
	new_folder.append("result");
	remove_all(new_folder);
	create_directory(new_folder);

	int i = 0;
	for (const auto& entry : directory_iterator(folder))
	{
		auto image_path = entry.path();
		std::cout << "processing " << entry.path()<<"\n";
		cv::Mat img = cv::imread(image_path.string());
		auto mats = visualize_hand_detection(img);
	
		path sub_dir = new_folder;
		sub_dir.append(image_path.filename().replace_extension("").string());
		create_directory(sub_dir);
		int i = 0;
		for (const auto& mat : mats)
		{
			cv::imwrite(sub_dir.string() + "/" + std::to_string(i) + ".png", mat);
			i++;
		}
		i++;
	}
}


/*
* tests the function finger_detector::rotate_image();
*/
void rotate_image_test()
{
	cv::Mat rect = cv::Mat(200, 400, CV_8UC1);
	rect = cv::Scalar(255);
	cv::imshow("before", rect);
	auto rotated = finger_detector::rotate_image(rect, cv::Point(50, 100), 45);
	cv::imshow("Rotated test", rotated);
	cv::waitKey();
}

int main()
{
	//process_images("D:\\Bachelorarbeit Dokumente\\hand pictures\\test");
	//process_images("C:\\Users\\wimmer\\hand pictures");
	//rotate_image_test();
	//extract_images_kinect();
	//test_hand_detection_single_image();
	hand_gesture_recognition_main(0, nullptr);
}